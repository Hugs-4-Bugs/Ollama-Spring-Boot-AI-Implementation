spring.application.name=ollama-spring-boot-implementation
#ChatModel myChatModel = ...
#ChatClient.Builder builder = ChatClient.builder(this.myChatModel);
#ChatClient chatClient = ChatClient.create(this.myChatModel);


spring.ai.ollama.chat.options.model = deepseek-r1:latest
#spring.ai.ollama.chat.options.model = mistral:latest
server.port = 8180
logging.level.org.springframework.web=DEBUG
logging.level.com.ollama=DEBUG
spring.webflux.enabled=true
spring.web.resources.add-mappings=false
server.address=0.0.0.0
spring.web.resources.static-locations=classpath:/static/
